# LiteCNN Pure C++ Inference Server ğŸ–¤

**ì´ˆê²½ëŸ‰ ë”¥ëŸ¬ë‹ ì¶”ë¡  ì„œë²„** - PyTorch ëª¨ë¸ì„ ìˆœìˆ˜ C++ë¡œ êµ¬í˜„í•œ ê²½ëŸ‰ ì¶”ë¡  ì—”ì§„

[![Memory](https://img.shields.io/badge/Memory-7MB-brightgreen.svg)](https://github.com)
[![C++17](https://img.shields.io/badge/C++-17-blue.svg)](https://isocpp.org/)
[![Platform](https://img.shields.io/badge/Platform-Linux%20%7C%20macOS%20%7C%20Windows-lightgrey.svg)](https://github.com)
[![Dual Server](https://img.shields.io/badge/Dual%20Server-AS--IS%20%2B%20TO--BE-orange.svg)](https://github.com)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-Auto%20Deploy-success.svg)](https://github.com)

## ğŸ¯ íŠ¹ì§•

- âš¡ **ì´ˆê²½ëŸ‰**: 7MB ë©”ëª¨ë¦¬ ì‚¬ìš© (PyTorch ëŒ€ë¹„ 95% ì ˆê°)
- ğŸš« **ì œë¡œ ì˜ì¡´ì„±**: í—¤ë” ì˜¨ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ë§Œ ì‚¬ìš©, ëŸ°íƒ€ì„ ì˜ì¡´ì„± ì—†ìŒ
- ğŸŒ **í•œêµ­ì–´ ì§€ì›**: 131ê°œ ê²¬ì¢…ì˜ ì˜ë¬¸/í•œê¸€ ì´ë¦„ ì œê³µ
- ğŸ”Œ **HTTP API**: RESTful APIë¡œ ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥
- ğŸ—ï¸ **í”„ë¡œë•ì…˜ ì¤€ë¹„**: ì—ëŸ¬ í•¸ë“¤ë§, ìë™ ì „ì²˜ë¦¬, JSON ì‘ë‹µ
- ğŸ“¦ **ë‹¨ì¼ ë°”ì´ë„ˆë¦¬**: 908KB ì‹¤í–‰ íŒŒì¼ í•˜ë‚˜ë¡œ ì™„ê²°
- ğŸ”¬ **ë“€ì–¼ ì„œë²„**: AS-IS (í”„ë¡œë•ì…˜) + TO-BE (ì‹¤í—˜) ë™ì‹œ ìš´ì˜
- ğŸ¤– **CI/CD**: GPU ì„œë²„ í•™ìŠµ ì™„ë£Œ ì‹œ ìë™ ë°°í¬ (~15ì´ˆ)

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| êµ¬í˜„ ë°©ì‹ | ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ | ê°ì†Œìœ¨ | ì˜ì¡´ì„± |
|-----------|---------------|--------|--------|
| FastAPI + PyTorch | 322 MB | - | Python, PyTorch, FastAPI |
| LibTorch C++ | 130 MB | 60% | LibTorch (~50-70MB) |
| ONNX Runtime | 102 MB | 68% | ONNX Runtime (~40MB) |
| **Pure C++** | **7 MB** | **98%** | **ì—†ìŒ** âœ… |

**ì‹¤ì¸¡ (M1 MacBook Air):**
- ë°”ì´ë„ˆë¦¬ í¬ê¸°: 908KB
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 7.3MB (í¬íŠ¸ë‹¹)
- ë°°í¬ ì‹œê°„: ~15ì´ˆ (GPU ì„œë²„ â†’ M1)
- ì¶”ë¡  ì‹œê°„: <100ms

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### í•„ìš” ì‚¬í•­

- C++17 í˜¸í™˜ ì»´íŒŒì¼ëŸ¬ (GCC 7+, Clang 5+, MSVC 2017+)
- CMake 3.14+
- Python 3.7+ (ê°€ì¤‘ì¹˜ ì¶”ì¶œìš©, ì„ íƒ ì‚¬í•­)

### ë¹Œë“œ

```bash
# Clone repository
git clone <repository-url>
cd litecnn-pure-cpp

# Build
mkdir -p build && cd build
cmake .. -DCMAKE_BUILD_TYPE=Release
make -j4

# Binary: build/litecnn_server (803KB)
```

### ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

ì‚¬ì „ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ:

```bash
# ëª¨ë¸ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ
wget https://huggingface.co/2c6829/litecnn-pure-cpp/resolve/main/model_weights.bin -P weights/

# í’ˆì¢… í´ë˜ìŠ¤ ë‹¤ìš´ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)
wget https://huggingface.co/2c6829/litecnn-pure-cpp/resolve/main/breed_classes.json
```

ë˜ëŠ” ìì‹ ì˜ PyTorch ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¶”ì¶œ:

```bash
python extract_weights.py /path/to/checkpoint.pth weights/model_weights.bin
```

### ì‹¤í–‰

#### ë‹¨ì¼ ì„œë²„

```bash
./build/litecnn_server --port 8891 --breeds breed_classes.json --weights weights/model_weights.bin
```

#### ë“€ì–¼ ì„œë²„ (AS-IS + TO-BE)

```bash
# ëª¨ë“  ì„œë²„ ì‹œì‘
./scripts/server_manager.sh start all

# ìƒíƒœ í™•ì¸
./scripts/server_manager.sh status
```

ì˜µì…˜:
- `--port PORT`: ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: 8080)
- `--weights PATH`: ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ (ê¸°ë³¸ê°’: `weights/model_weights.bin`)
- `--breeds PATH`: í’ˆì¢… JSON ê²½ë¡œ (ê¸°ë³¸ê°’: `breed_classes.json`)

## ğŸ“¡ API ì‚¬ìš©ë²•

### Health Check

```bash
curl http://localhost:8891/health
```

ì‘ë‹µ:
```json
{"status": "ok"}
```

### ì´ë¯¸ì§€ ì¶”ë¡ 

```bash
curl -X POST http://localhost:8891/predict \
  -F "image=@dog.jpg"
```

ì‘ë‹µ:
```json
{
  "predictions": [
    {
      "class_id": 81,
      "score": 0.9523,
      "breed_en": "Border collie",
      "breed_ko": "ë³´ë” ì½œë¦¬"
    },
    {
      "class_id": 106,
      "score": 0.0321,
      "breed_en": "Samoyed",
      "breed_ko": "ì‚¬ëª¨ì˜ˆë“œ"
    }
  ]
}
```

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

### ì „ì²´ êµ¬ì¡°

```
HTTP Request (JPEG/PNG)
    â†“
Image Decoder (stb_image)
    â†“
Resize â†’ 224x224 (stb_image_resize)
    â†“
Normalize (ImageNet mean/std)
    â†“
LiteCNNPro Forward Pass
    â”œâ”€ Stem (Conv2D + BN + ReLU6)
    â”œâ”€ 7x DepthwiseSeparableConv blocks
    â”‚   â””â”€ SE (Squeeze-Excitation) attention
    â””â”€ Classifier (512â†’256â†’120)
    â†“
Softmax + Top-5
    â†“
JSON Response (breed names + scores)
```

### ëª¨ë¸: LiteCNNPro

- **íŒŒë¼ë¯¸í„°**: 600K
- **í´ë˜ìŠ¤**: 120 (Stanford Dogs)
- **ì…ë ¥**: 224Ã—224 RGB
- **ì¶œë ¥**: 120-dim logits

**ë ˆì´ì–´ êµ¬ì„±**:
1. Stem: Conv2D(3â†’32) + BatchNorm + ReLU6
2. Features: 7x Depthwise Separable Conv blocks
   - Block 0: 32â†’64 (stride 2)
   - Block 1: 64â†’128 (stride 2)
   - Block 2-3: 128â†’256 (stride 2)
   - Block 4-6: 256â†’512
   - SE (Squeeze-Excitation) attention
3. Classifier: AdaptiveAvgPool â†’ FC(512â†’256) â†’ FC(256â†’120)

### ì˜ì¡´ì„± (í—¤ë” ì˜¨ë¦¬)

```
third_party/
â”œâ”€â”€ httplib.h          # HTTP ì„œë²„ (cpp-httplib)
â”œâ”€â”€ stb_image.h        # ì´ë¯¸ì§€ ë””ì½”ë”©
â”œâ”€â”€ stb_image_resize2.h # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì§•
â””â”€â”€ json.hpp           # JSON (nlohmann/json)
```

ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í—¤ë” ì˜¨ë¦¬ì´ë¯€ë¡œ **ëŸ°íƒ€ì„ ì˜ì¡´ì„± ì—†ìŒ**.

## ğŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
litecnn-pure-cpp/
â”œâ”€â”€ CMakeLists.txt          # CMake ë¹Œë“œ ì„¤ì •
â”œâ”€â”€ README.md               # ì´ íŒŒì¼
â”œâ”€â”€ breed_classes.json      # 120ê°œ ê²¬ì¢… ì˜ë¬¸/í•œê¸€ ì´ë¦„
â”œâ”€â”€ build/                  # ë¹Œë“œ ê²°ê³¼ë¬¼
â”‚   â””â”€â”€ litecnn_server      # ì‹¤í–‰ íŒŒì¼ (803KB)
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ adr/                # Architecture Decision Records
â”‚       â””â”€â”€ 001-pure-cpp-implementation.md
â”œâ”€â”€ include/                # í—¤ë” íŒŒì¼
â”‚   â”œâ”€â”€ tensor.h            # Tensor êµ¬ì¡°ì²´
â”‚   â”œâ”€â”€ layers.h            # CNN ë ˆì´ì–´ êµ¬í˜„
â”‚   â”œâ”€â”€ model.h             # LiteCNNPro ëª¨ë¸
â”‚   â””â”€â”€ server.h            # HTTP ì„œë²„
â”œâ”€â”€ src/                    # êµ¬í˜„ íŒŒì¼
â”‚   â”œâ”€â”€ tensor.cpp          # Tensor ì—°ì‚° (114ì¤„)
â”‚   â”œâ”€â”€ layers.cpp          # CNN ë ˆì´ì–´ (356ì¤„)
â”‚   â”œâ”€â”€ model.cpp           # ëª¨ë¸ forward (246ì¤„)
â”‚   â”œâ”€â”€ server.cpp          # HTTP ì„œë²„ (162ì¤„)
â”‚   â””â”€â”€ main.cpp            # Entry point (38ì¤„)
â”œâ”€â”€ third_party/            # í—¤ë” ì˜¨ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
â”œâ”€â”€ scripts/                # ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ extract_weights_remote.sh
â”‚   â”œâ”€â”€ create_dummy_weights.py
â”‚   â””â”€â”€ test_memory.sh
â””â”€â”€ weights/                # ëª¨ë¸ ê°€ì¤‘ì¹˜
    â””â”€â”€ model_weights.bin   # 4.0MB
```

**ì´ ì½”ë“œ**: 916ì¤„ (ì£¼ì„ ì œì™¸)

## ğŸ”§ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### Tensor êµ¬ì¡°

```cpp
struct Tensor {
    std::vector<int> shape;      // [N, C, H, W]
    std::vector<float> data;     // NCHW ë©”ëª¨ë¦¬ ë ˆì´ì•„ì›ƒ
};
```

### êµ¬í˜„ëœ ë ˆì´ì–´

1. **Conv2D**: Standard & Depthwise convolution
2. **BatchNorm2D**: Inference mode (running mean/var)
3. **Linear**: Fully connected layer
4. **AdaptiveAvgPool2D**: Global average pooling
5. **ReLU6**: Clipped ReLU activation
6. **Sigmoid**: Logistic activation
7. **SE Block**: Squeeze-Excitation channel attention
8. **Depthwise Separable Conv**: Depthwise + Pointwise

### ê°€ì¤‘ì¹˜ í¬ë§·

Binary format (Big Endian):

```
[Magic: "LCNN"] [Version: uint32] [Num Tensors: uint32]

For each tensor:
  [Name Length: uint32] [Name: char[]]
  [Rank: uint32] [Shape: uint32[rank]]
  [Data: float[product(shape)]]
```

Example:
```
4C 43 4E 4E  00 00 00 01  00 00 00 6C  00 00 00 13  # "LCNN", v1, 108 tensors, name_len=19
73 74 65 6D 2E 30 2E 77 65 69 67 68 74           # "stem.0.weight"
00 00 00 04                                       # rank=4
00 00 00 20 00 00 00 03 00 00 00 03 00 00 00 03  # shape=[32,3,3,3]
3F 80 00 00 BF 00 00 00 ...                       # float data
```

## ğŸ“ í•™ìŠµí•œ êµí›ˆ

### 1. ì˜ì¡´ì„±ì´ ì ì„ìˆ˜ë¡ ë©”ëª¨ë¦¬ íš¨ìœ¨ì 

PyTorch/LibTorchì˜ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëŒ€ë¶€ë¶„ì€ **ëŸ°íƒ€ì„ ë¼ì´ë¸ŒëŸ¬ë¦¬**ê°€ ì°¨ì§€í•©ë‹ˆë‹¤:
- LibTorch: ~50-70MB (ì¶”ë¡  ì—”ì§„ + CUDA ì§€ì› ë“±)
- ONNX Runtime: ~40MB (ìµœì í™”ëœ ì¶”ë¡  ì „ìš© ì—”ì§„)

Pure C++ëŠ” **í•„ìš”í•œ ë ˆì´ì–´ë§Œ êµ¬í˜„**í•˜ë¯€ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½ì´ ê·¹ëŒ€í™”ë©ë‹ˆë‹¤.

### 2. í—¤ë” ì˜¨ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ì¥ì 

- **ë°°í¬ ë‹¨ìˆœí™”**: ë‹¨ì¼ ë°”ì´ë„ˆë¦¬, ì„¤ì¹˜ ë¶ˆí•„ìš”
- **ìµœì í™” ê°€ëŠ¥ì„±**: ì»´íŒŒì¼ íƒ€ì„ì— ì „ì²´ ì½”ë“œ ìµœì í™”
- **ì´ì‹ì„±**: í”Œë«í¼ ê°„ ì´ë™ ìš©ì´

### 3. ì¡°ê¸° ìµœì í™”ê°€ í•„ìš”í•  ë•Œ

ë©”ëª¨ë¦¬ ì œì•½ì´ **ëª…í™•í•˜ê³  ì—„ê²©**í•œ ê²½ìš° (ì˜ˆ: < 50MB), ì²˜ìŒë¶€í„° Pure C++ ê³ ë ¤í•˜ëŠ” ê²ƒì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤.

### 4. í•œêµ­ì–´ ì§€ì›ì€ ì‰½ë‹¤

JSON ë§¤í•‘ë§Œìœ¼ë¡œ ë‹¤êµ­ì–´ ì§€ì›ì´ ê°„ë‹¨íˆ í•´ê²°ë©ë‹ˆë‹¤:

```json
{
  "81": {
    "en": "Border collie",
    "ko": "ë³´ë” ì½œë¦¬"
  }
}
```

## ğŸ”® í–¥í›„ ê°œì„  ì‚¬í•­

### ì„±ëŠ¥ ìµœì í™”

- [ ] **SIMD ìµœì í™”**: AVX2/NEONì„ í™œìš©í•œ ë²¡í„°í™”
- [ ] **ë©€í‹°ìŠ¤ë ˆë”©**: ë°°ì¹˜ ì¶”ë¡  ë³‘ë ¬ ì²˜ë¦¬
- [ ] **Quantization**: INT8 ì–‘ìí™”ë¡œ ë©”ëª¨ë¦¬ 50% ì¶”ê°€ ì ˆê°

### ê¸°ëŠ¥ ì¶”ê°€

- [ ] **ë°°ì¹˜ ì¶”ë¡ **: ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬
- [ ] **ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë°**: ì‹¤ì‹œê°„ ë¹„ë””ì˜¤ ì¶”ë¡ 
- [ ] **ëª¨ë¸ ì—…ë°ì´íŠ¸**: ëŸ°íƒ€ì„ hot-reload
- [ ] **ë©”íŠ¸ë¦­**: Prometheus í†µí•©

### ë°°í¬

- [ ] **Docker ì´ë¯¸ì§€**: Alpine Linux ê¸°ë°˜ (~10MB)
- [ ] **ì‹œìŠ¤í…œ ì„œë¹„ìŠ¤**: systemd/launchd í†µí•©
- [ ] **ë²¤ì¹˜ë§ˆí¬**: ìë™í™”ëœ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

## ğŸ”¬ ë“€ì–¼ ì„œë²„ ì•„í‚¤í…ì²˜

AS-IS (í”„ë¡œë•ì…˜)ì™€ TO-BE (ì‹¤í—˜) ëª¨ë¸ì„ ë™ì‹œì— ìš´ì˜í•˜ì—¬ ì•ˆì „í•œ ëª¨ë¸ ë¹„êµ ë° ë°°í¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

```
í¬íŠ¸ 8891 (AS-IS)  â†’ weights/model_8891.bin (ìˆ˜ë™ ë°°í¬, ì•ˆì • ë²„ì „)
í¬íŠ¸ 8892 (TO-BE)  â†’ weights/model_8892.bin (ìë™ ë°°í¬, ì‹¤í—˜ ë²„ì „)
```

### ì„œë²„ ê´€ë¦¬

```bash
# ëª¨ë“  ì„œë²„ ì‹œì‘/ì¤‘ì§€/ì¬ì‹œì‘
./scripts/server_manager.sh [start|stop|restart] all

# ê°œë³„ ì„œë²„ ì œì–´
./scripts/server_manager.sh restart 8891  # AS-ISë§Œ ì¬ì‹œì‘

# ìƒíƒœ í™•ì¸
./scripts/server_manager.sh status
```

### A/B ë¹„êµ

```bash
# AS-IS
curl -X POST http://localhost:8891/predict -F "image=@test.jpg"

# TO-BE
curl -X POST http://localhost:8892/predict -F "image=@test.jpg"
```

ìƒì„¸ ë¬¸ì„œ: [DUAL_SERVER.md](docs/DUAL_SERVER.md), [AB_TESTING.md](docs/AB_TESTING.md)

## ğŸ¤– CI/CD íŒŒì´í”„ë¼ì¸

GPU ì„œë²„ì—ì„œ í•™ìŠµ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ TO-BE ëª¨ë¸ì„ ë°°í¬í•©ë‹ˆë‹¤ (~15ì´ˆ).

```
GPU ì„œë²„ í•™ìŠµ ì™„ë£Œ
    â†“ (MD5 í•´ì‹œ ë³€ê²½ ê°ì§€)
ì²´í¬í¬ì¸íŠ¸ ë‹¤ìš´ë¡œë“œ (SCP)
    â†“
PyTorch â†’ Binary ë³€í™˜
    â†“
C++ ë¹Œë“œ
    â†“
TO-BE ì„œë²„ ì¬ì‹œì‘ (8892)
    â†“
âœ… ë°°í¬ ì™„ë£Œ
```

### ìˆ˜ë™ ë°°í¬

```bash
./scripts/deploy_from_gpu.sh
```

### ìë™ ë°°í¬ (30ë¶„ë§ˆë‹¤)

```bash
# macOS launchd ë“±ë¡
launchctl load ~/Library/LaunchAgents/com.litecnn.autodeploy.plist
```

**ì•Œë¦¼**: Discord + Telegram ë™ì‹œ ì „ì†¡ (Telegram ì„¤ì • í•„ìš”)

ìƒì„¸ ë¬¸ì„œ: [CICD.md](docs/CICD.md), [AUTOMATION.md](docs/AUTOMATION.md), [TELEGRAM_SETUP.md](docs/TELEGRAM_SETUP.md)

## ğŸ“ ADR (Architecture Decision Records)

ìƒì„¸í•œ ì•„í‚¤í…ì²˜ ê²°ì • ê³¼ì •ì€ [ADR-001](docs/adr/001-pure-cpp-implementation.md)ì„ ì°¸ê³ í•˜ì„¸ìš”.

## ğŸ“„ ë¼ì´ì„ ìŠ¤

MIT License

## ğŸ™ ê°ì‚¬ì˜ ë§

- **cpp-httplib**: ê°„ë‹¨í•˜ê³  ê°•ë ¥í•œ HTTP ì„œë²„
- **stb**: ì‹ ì˜ ì„ ë¬¼ ê°™ì€ í—¤ë” ì˜¨ë¦¬ ë¼ì´ë¸ŒëŸ¬ë¦¬
- **nlohmann/json**: ìµœê³ ì˜ C++ JSON ë¼ì´ë¸ŒëŸ¬ë¦¬

## ğŸ”— Links

- **GitHub**: https://github.com/stupidcoderJung/litecnn-pure-cpp
- **Hugging Face Model**: https://huggingface.co/2c6829/litecnn-pure-cpp
- **Issues**: https://github.com/stupidcoderJung/litecnn-pure-cpp/issues

---

**Date**: 2026-02-06  
**Memory Usage**: 7MB per server (95% reduction from PyTorch)  
**Dual Server**: AS-IS (8891) + TO-BE (8892)  
**Status**: Production Ready âœ…

## MPS-Accelerated Server (Port 8893)

**NEW!** LibTorch + Metal Performance Shaders ìµœì í™” ì„œë²„

### ì„±ëŠ¥
- **Inference**: 6-8ms (Pure C++ ëŒ€ë¹„ 35ë°° ë¹ ë¦„)
- **Device**: M1 GPU (MPS)
- **Model**: Cycle 13 (62.60% accuracy)
- **Features**: 
  - í•œêµ­ì–´/ì˜ì–´ ê²¬ì¢… ì´ë¦„
  - Multipart ì´ë¯¸ì§€ ì—…ë¡œë“œ
  - MPS GPU ê°€ì†

### ë¹Œë“œ ë° ì‹¤í–‰
```bash
# ë¹Œë“œ
make -f Makefile.mps

# ì‹¤í–‰
./build/litecnn_server_mps
```

### API
```bash
# Health check
curl http://localhost:8893/health

# ì´ë¯¸ì§€ ì—…ë¡œë“œ
curl -X POST http://localhost:8893/predict \
  -F "image=@/path/to/dog.jpg" | jq

# JSON ê²½ë¡œ
curl -X POST http://localhost:8893/predict \
  -H "Content-Type: application/json" \
  -d '{"image_path": "/path/to/dog.jpg", "top_k": 3}' | jq
```

### ì‘ë‹µ ì˜ˆì‹œ
```json
{
  "predictions": [
    {
      "rank": 1,
      "class_id": 12,
      "breed_en": "Border collie",
      "breed_ko": "ë³´ë” ì½œë¦¬",
      "confidence": 57.08
    }
  ],
  "timing": {
    "total_ms": 11.103,
    "preprocess_ms": 6.997,
    "inference_ms": 7.486,
    "transfer_ms": 3.509
  }
}
```

## Dual MPS Server Architecture

### Port Configuration
- **8891**: Cycle 11 MPS (Production, 68.36% accuracy)
  - Stable, proven model
  - ~4-5ms inference
  
- **8892**: Cycle N MPS (Latest, experimental)
  - Auto-deployed from GPU server
  - Test new models before promotion to 8891

### Usage
```bash
# Production (Cycle 11)
curl -X POST http://192.168.0.59:8891/predict \
  -F "image=@dog.jpg" | jq

# Latest (Cycle N)
curl -X POST http://192.168.0.59:8892/predict \
  -F "image=@dog.jpg" | jq
```

### Deployment
```bash
# Deploy new cycle to 8892
bash scripts/mps/deploy_latest.sh 14

# If satisfied, promote to 8891:
# 1. Stop 8891
# 2. Convert and deploy new cycle to 8891
# 3. Restart
```
